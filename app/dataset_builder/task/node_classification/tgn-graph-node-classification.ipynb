{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Device: local\n"
     ]
    }
   ],
   "source": [
    "# This code achieves a performance of around 96.60%. However, it is not\n",
    "# directly comparable to the results reported by the TGN paper since a\n",
    "# slightly different evaluation setup is used here.\n",
    "# In particular, predictions in the same batch are made in parallel, i.e.\n",
    "# predictions for interactions later in the batch have no access to any\n",
    "# information whatsoever about previous interactions in the same batch.\n",
    "# On the contrary, when sampling node neighborhoods for interactions later in\n",
    "# the batch, the TGN paper code has access to previous interactions in the\n",
    "# batch.\n",
    "# While both approaches are correct, together with the authors of the paper we\n",
    "# decided to present this version here as it is more realsitic and a better\n",
    "# test bed for future methods.\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/app')\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "from torch_geometric.nn.models.tgn import (\n",
    "    IdentityMessage,\n",
    "    LastAggregator,\n",
    "    LastNeighborLoader,\n",
    ")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scenario_identification.utils.early_stopper import EarlyStopper\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import TemporalData,InMemoryDataset\n",
    "import argparse\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from scenario_identification.utils.path_helper import get_dataset_path, get_in_memory_dataset_path\n",
    "\n",
    "\n",
    "import scenario_identification.utils.path_helper as path_helper\n",
    "import scenario_identification.utils.data_loader as loader\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "BUILD_DEVICE='local'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BUILD_DEVICE = os.getenv(\"BUILD_DEVICE\")\n",
    "print(f\"Build Device: {BUILD_DEVICE}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scenario_identification.utils.path_helper import DatasetType\n",
    "\n",
    "\n",
    "DATASET_TYPE = DatasetType.NODE_CLASSIFICATION_SITUATION_LABELS.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/app/scenario_identification/task/node_classification/tgn-graph-node-classification.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/app/scenario_identification/task/node_classification/tgn-graph-node-classification.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m args\u001b[39m=\u001b[39mArgs()\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/app/scenario_identification/task/node_classification/tgn-graph-node-classification.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m BATCH_SIZE \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mbs\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d61726975732f446f63756d656e74732f53696d756c6174696f6e2d54727573742d5265636f6d6d656e646174696f6e2f43616e62657272612d536d616c6c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/app/scenario_identification/task/node_classification/tgn-graph-node-classification.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m NUM_NEIGHBORS \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mn_degree\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Args' is not defined"
     ]
    }
   ],
   "source": [
    "args=Args()\n",
    "\n",
    "BATCH_SIZE = args.bs\n",
    "NUM_NEIGHBORS = args.n_degree\n",
    "NUM_NEG = 1\n",
    "NUM_EPOCH = args.n_epoch\n",
    "NUM_HEADS = args.n_head\n",
    "DROP_OUT = args.drop_out\n",
    "GPU = args.gpu\n",
    "DATA = args.data\n",
    "NUM_LAYER = args.n_layer\n",
    "LEARNING_RATE = args.lr\n",
    "NODE_DIM = args.node_dim\n",
    "TIME_DIM = args.time_dim\n",
    "USE_MEMORY = args.use_memory\n",
    "MESSAGE_DIM = args.message_dim\n",
    "MEMORY_DIM = args.memory_dim\n",
    "\n",
    "dataset_path = get_dataset_path(DATASET_TYPE, BUILD_DEVICE)\n",
    "memory_dataset_path = get_in_memory_dataset_path(DATASET_TYPE, BUILD_DEVICE)\n",
    "\n",
    "dataset = loader.get_dataframe(dataset_path)\n",
    "dataset = loader.remove_self_loops(dataset)\n",
    "\n",
    "\n",
    "data, slices = loader.process_node_classification_situation_label_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = get_dataset_path(DATASET_TYPE, BUILD_DEVICE)\n",
    "memory_dataset_path = get_in_memory_dataset_path(DATASET_TYPE, BUILD_DEVICE)\n",
    "\n",
    "\n",
    "dataset = data = pd.read_csv(\"/app/scenario_identification/data/iot-unsw_node_classification/ml_iot-unsw_situation_labels.csv\")\n",
    "data_array = dataset.to_numpy()\n",
    "\n",
    "post_label_idx = dataset.columns.get_loc('situation_label')\n",
    "u_idx = dataset.columns.get_loc('device_id')\n",
    "\n",
    "filtered_array = data_array[data_array[:, post_label_idx] != -1]\n",
    "dataset = pd.DataFrame(filtered_array, columns=dataset.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array = dataset.to_numpy()\n",
    "\n",
    "# shape_status_idx = dataset.columns.get_loc('shape_status_DEFORMED')\n",
    "# label_idx = dataset.columns.get_loc('situation_label')\n",
    "\n",
    "# data_array[data_array[:, shape_status_idx] == 1, label_idx] = 1\n",
    "# data_array[data_array[:, shape_status_idx] == 0, label_idx] += 0\n",
    "# dataset = pd.DataFrame(data_array, columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>time</th>\n",
       "      <th>situation_label</th>\n",
       "      <th>device_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>shape_status_DEFORMED</th>\n",
       "      <th>shape_status_ORIGINAL_MANUFACTURED</th>\n",
       "      <th>signal</th>\n",
       "      <th>speed</th>\n",
       "      <th>status_ACTIVE</th>\n",
       "      <th>status_ERROR</th>\n",
       "      <th>status_INACTIVE</th>\n",
       "      <th>type_EMERGENCY_CENTER</th>\n",
       "      <th>type_INDUCTION_LOOP</th>\n",
       "      <th>type_SMART_PHONE</th>\n",
       "      <th>type_TRAFFIC_CAMERA</th>\n",
       "      <th>type_TRAFFIC_LIGHT</th>\n",
       "      <th>type_VEHICLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>4254</td>\n",
       "      <td>39</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>4298</td>\n",
       "      <td>39</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350</th>\n",
       "      <td>4350</td>\n",
       "      <td>39</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>4393</td>\n",
       "      <td>39</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>4443</td>\n",
       "      <td>39</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>4485</td>\n",
       "      <td>39</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>4532</td>\n",
       "      <td>39</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>4578</td>\n",
       "      <td>39</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>4623</td>\n",
       "      <td>39</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>4665</td>\n",
       "      <td>39</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>4712</td>\n",
       "      <td>39</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>4757</td>\n",
       "      <td>39</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>4791</td>\n",
       "      <td>39</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>4848</td>\n",
       "      <td>39</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>4899</td>\n",
       "      <td>39</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>4941</td>\n",
       "      <td>39</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>39</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>5046</td>\n",
       "      <td>39</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>5095</td>\n",
       "      <td>39</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>5144</td>\n",
       "      <td>39</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>5193</td>\n",
       "      <td>39</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5242</th>\n",
       "      <td>5242</td>\n",
       "      <td>39</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>5289</td>\n",
       "      <td>39</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>5340</td>\n",
       "      <td>39</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>5389</td>\n",
       "      <td>39</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>5429</td>\n",
       "      <td>39</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>5487</td>\n",
       "      <td>39</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>5521</td>\n",
       "      <td>39</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>5585</td>\n",
       "      <td>39</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>5639</td>\n",
       "      <td>39</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5680</td>\n",
       "      <td>39</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>5739</td>\n",
       "      <td>39</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>5791</td>\n",
       "      <td>39</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>5843</td>\n",
       "      <td>39</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>5895</td>\n",
       "      <td>39</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>5947</td>\n",
       "      <td>39</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>6000</td>\n",
       "      <td>39</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>6052</td>\n",
       "      <td>39</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6096</td>\n",
       "      <td>39</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>6149</td>\n",
       "      <td>39</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>6208</td>\n",
       "      <td>39</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>6263</td>\n",
       "      <td>39</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>6315</td>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>6369</td>\n",
       "      <td>39</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>6422</td>\n",
       "      <td>39</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>6475</td>\n",
       "      <td>39</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>6528</td>\n",
       "      <td>39</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>6565</td>\n",
       "      <td>39</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>6633</td>\n",
       "      <td>39</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>6690</td>\n",
       "      <td>39</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>veh6</td>\n",
       "      <td>402.11</td>\n",
       "      <td>288.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 device_id time situation_label device_name latitude longitude  \\\n",
       "4254       4254        39  150               1        veh6   402.11    288.55   \n",
       "4298       4298        39  151               1        veh6   402.11    288.55   \n",
       "4350       4350        39  152               1        veh6   402.11    288.55   \n",
       "4393       4393        39  153               1        veh6   402.11    288.55   \n",
       "4443       4443        39  154               1        veh6   402.11    288.55   \n",
       "4485       4485        39  155               1        veh6   402.11    288.55   \n",
       "4532       4532        39  156               1        veh6   402.11    288.55   \n",
       "4578       4578        39  157               1        veh6   402.11    288.55   \n",
       "4623       4623        39  158               1        veh6   402.11    288.55   \n",
       "4665       4665        39  159               1        veh6   402.11    288.55   \n",
       "4712       4712        39  160               1        veh6   402.11    288.55   \n",
       "4757       4757        39  161               1        veh6   402.11    288.55   \n",
       "4791       4791        39  162               1        veh6   402.11    288.55   \n",
       "4848       4848        39  163               1        veh6   402.11    288.55   \n",
       "4899       4899        39  164               1        veh6   402.11    288.55   \n",
       "4941       4941        39  165               1        veh6   402.11    288.55   \n",
       "4997       4997        39  166               1        veh6   402.11    288.55   \n",
       "5046       5046        39  167               1        veh6   402.11    288.55   \n",
       "5095       5095        39  168               1        veh6   402.11    288.55   \n",
       "5144       5144        39  169               1        veh6   402.11    288.55   \n",
       "5193       5193        39  170               1        veh6   402.11    288.55   \n",
       "5242       5242        39  171               1        veh6   402.11    288.55   \n",
       "5289       5289        39  172               1        veh6   402.11    288.55   \n",
       "5340       5340        39  173               1        veh6   402.11    288.55   \n",
       "5389       5389        39  174               1        veh6   402.11    288.55   \n",
       "5429       5429        39  175               1        veh6   402.11    288.55   \n",
       "5487       5487        39  176               1        veh6   402.11    288.55   \n",
       "5521       5521        39  177               1        veh6   402.11    288.55   \n",
       "5585       5585        39  178               1        veh6   402.11    288.55   \n",
       "5639       5639        39  179               1        veh6   402.11    288.55   \n",
       "5680       5680        39  180               1        veh6   402.11    288.55   \n",
       "5739       5739        39  181               1        veh6   402.11    288.55   \n",
       "5791       5791        39  182               1        veh6   402.11    288.55   \n",
       "5843       5843        39  183               1        veh6   402.11    288.55   \n",
       "5895       5895        39  184               1        veh6   402.11    288.55   \n",
       "5947       5947        39  185               1        veh6   402.11    288.55   \n",
       "6000       6000        39  186               1        veh6   402.11    288.55   \n",
       "6052       6052        39  187               1        veh6   402.11    288.55   \n",
       "6096       6096        39  188               1        veh6   402.11    288.55   \n",
       "6149       6149        39  189               1        veh6   402.11    288.55   \n",
       "6208       6208        39  190               1        veh6   402.11    288.55   \n",
       "6263       6263        39  191               1        veh6   402.11    288.55   \n",
       "6315       6315        39  192               1        veh6   402.11    288.55   \n",
       "6369       6369        39  193               1        veh6   402.11    288.55   \n",
       "6422       6422        39  194               1        veh6   402.11    288.55   \n",
       "6475       6475        39  195               1        veh6   402.11    288.55   \n",
       "6528       6528        39  196               1        veh6   402.11    288.55   \n",
       "6565       6565        39  197               1        veh6   402.11    288.55   \n",
       "6633       6633        39  198               1        veh6   402.11    288.55   \n",
       "6690       6690        39  199               1        veh6   402.11    288.55   \n",
       "\n",
       "     shape_status_DEFORMED shape_status_ORIGINAL_MANUFACTURED signal speed  \\\n",
       "4254                   0.0                                1.0   10.0   0.0   \n",
       "4298                   0.0                                1.0   10.0   0.0   \n",
       "4350                   0.0                                1.0   10.0   0.0   \n",
       "4393                   0.0                                1.0   10.0   0.0   \n",
       "4443                   0.0                                1.0   10.0   0.0   \n",
       "4485                   0.0                                1.0   10.0   0.0   \n",
       "4532                   0.0                                1.0   10.0   0.0   \n",
       "4578                   0.0                                1.0   10.0   0.0   \n",
       "4623                   0.0                                1.0   10.0   0.0   \n",
       "4665                   0.0                                1.0   10.0   0.0   \n",
       "4712                   0.0                                1.0   10.0   0.0   \n",
       "4757                   0.0                                1.0   10.0   0.0   \n",
       "4791                   0.0                                1.0   10.0   0.0   \n",
       "4848                   0.0                                1.0   10.0   0.0   \n",
       "4899                   0.0                                1.0   10.0   0.0   \n",
       "4941                   0.0                                1.0   10.0   0.0   \n",
       "4997                   0.0                                1.0   10.0   0.0   \n",
       "5046                   0.0                                1.0   10.0   0.0   \n",
       "5095                   0.0                                1.0   10.0   0.0   \n",
       "5144                   0.0                                1.0   10.0   0.0   \n",
       "5193                   0.0                                1.0   10.0   0.0   \n",
       "5242                   0.0                                1.0   10.0   0.0   \n",
       "5289                   0.0                                1.0   10.0   0.0   \n",
       "5340                   0.0                                1.0   10.0   0.0   \n",
       "5389                   0.0                                1.0   10.0   0.0   \n",
       "5429                   0.0                                1.0   10.0   0.0   \n",
       "5487                   0.0                                1.0   10.0   0.0   \n",
       "5521                   0.0                                1.0   10.0   0.0   \n",
       "5585                   0.0                                1.0   10.0   0.0   \n",
       "5639                   0.0                                1.0   10.0   0.0   \n",
       "5680                   0.0                                1.0   10.0   0.0   \n",
       "5739                   0.0                                1.0   10.0   0.0   \n",
       "5791                   0.0                                1.0   10.0   0.0   \n",
       "5843                   0.0                                1.0   10.0   0.0   \n",
       "5895                   0.0                                1.0   10.0   0.0   \n",
       "5947                   0.0                                1.0   10.0   0.0   \n",
       "6000                   0.0                                1.0   10.0   0.0   \n",
       "6052                   0.0                                1.0   10.0   0.0   \n",
       "6096                   0.0                                1.0   10.0   0.0   \n",
       "6149                   0.0                                1.0   10.0   0.0   \n",
       "6208                   0.0                                1.0   10.0   0.0   \n",
       "6263                   0.0                                1.0   10.0   0.0   \n",
       "6315                   0.0                                1.0   10.0   0.0   \n",
       "6369                   0.0                                1.0   10.0   0.0   \n",
       "6422                   0.0                                1.0   10.0   0.0   \n",
       "6475                   0.0                                1.0   10.0   0.0   \n",
       "6528                   0.0                                1.0   10.0   0.0   \n",
       "6565                   0.0                                1.0   10.0   0.0   \n",
       "6633                   0.0                                1.0   10.0   0.0   \n",
       "6690                   0.0                                1.0   10.0   0.0   \n",
       "\n",
       "     status_ACTIVE status_ERROR status_INACTIVE type_EMERGENCY_CENTER  \\\n",
       "4254           1.0          0.0             0.0                   0.0   \n",
       "4298           1.0          0.0             0.0                   0.0   \n",
       "4350           1.0          0.0             0.0                   0.0   \n",
       "4393           1.0          0.0             0.0                   0.0   \n",
       "4443           1.0          0.0             0.0                   0.0   \n",
       "4485           1.0          0.0             0.0                   0.0   \n",
       "4532           1.0          0.0             0.0                   0.0   \n",
       "4578           1.0          0.0             0.0                   0.0   \n",
       "4623           1.0          0.0             0.0                   0.0   \n",
       "4665           1.0          0.0             0.0                   0.0   \n",
       "4712           1.0          0.0             0.0                   0.0   \n",
       "4757           1.0          0.0             0.0                   0.0   \n",
       "4791           1.0          0.0             0.0                   0.0   \n",
       "4848           1.0          0.0             0.0                   0.0   \n",
       "4899           1.0          0.0             0.0                   0.0   \n",
       "4941           1.0          0.0             0.0                   0.0   \n",
       "4997           1.0          0.0             0.0                   0.0   \n",
       "5046           1.0          0.0             0.0                   0.0   \n",
       "5095           1.0          0.0             0.0                   0.0   \n",
       "5144           1.0          0.0             0.0                   0.0   \n",
       "5193           1.0          0.0             0.0                   0.0   \n",
       "5242           1.0          0.0             0.0                   0.0   \n",
       "5289           1.0          0.0             0.0                   0.0   \n",
       "5340           1.0          0.0             0.0                   0.0   \n",
       "5389           1.0          0.0             0.0                   0.0   \n",
       "5429           1.0          0.0             0.0                   0.0   \n",
       "5487           1.0          0.0             0.0                   0.0   \n",
       "5521           1.0          0.0             0.0                   0.0   \n",
       "5585           1.0          0.0             0.0                   0.0   \n",
       "5639           1.0          0.0             0.0                   0.0   \n",
       "5680           1.0          0.0             0.0                   0.0   \n",
       "5739           1.0          0.0             0.0                   0.0   \n",
       "5791           1.0          0.0             0.0                   0.0   \n",
       "5843           1.0          0.0             0.0                   0.0   \n",
       "5895           1.0          0.0             0.0                   0.0   \n",
       "5947           1.0          0.0             0.0                   0.0   \n",
       "6000           1.0          0.0             0.0                   0.0   \n",
       "6052           1.0          0.0             0.0                   0.0   \n",
       "6096           1.0          0.0             0.0                   0.0   \n",
       "6149           1.0          0.0             0.0                   0.0   \n",
       "6208           1.0          0.0             0.0                   0.0   \n",
       "6263           1.0          0.0             0.0                   0.0   \n",
       "6315           1.0          0.0             0.0                   0.0   \n",
       "6369           1.0          0.0             0.0                   0.0   \n",
       "6422           1.0          0.0             0.0                   0.0   \n",
       "6475           1.0          0.0             0.0                   0.0   \n",
       "6528           1.0          0.0             0.0                   0.0   \n",
       "6565           1.0          0.0             0.0                   0.0   \n",
       "6633           1.0          0.0             0.0                   0.0   \n",
       "6690           1.0          0.0             0.0                   0.0   \n",
       "\n",
       "     type_INDUCTION_LOOP type_SMART_PHONE type_TRAFFIC_CAMERA  \\\n",
       "4254                 0.0              0.0                 0.0   \n",
       "4298                 0.0              0.0                 0.0   \n",
       "4350                 0.0              0.0                 0.0   \n",
       "4393                 0.0              0.0                 0.0   \n",
       "4443                 0.0              0.0                 0.0   \n",
       "4485                 0.0              0.0                 0.0   \n",
       "4532                 0.0              0.0                 0.0   \n",
       "4578                 0.0              0.0                 0.0   \n",
       "4623                 0.0              0.0                 0.0   \n",
       "4665                 0.0              0.0                 0.0   \n",
       "4712                 0.0              0.0                 0.0   \n",
       "4757                 0.0              0.0                 0.0   \n",
       "4791                 0.0              0.0                 0.0   \n",
       "4848                 0.0              0.0                 0.0   \n",
       "4899                 0.0              0.0                 0.0   \n",
       "4941                 0.0              0.0                 0.0   \n",
       "4997                 0.0              0.0                 0.0   \n",
       "5046                 0.0              0.0                 0.0   \n",
       "5095                 0.0              0.0                 0.0   \n",
       "5144                 0.0              0.0                 0.0   \n",
       "5193                 0.0              0.0                 0.0   \n",
       "5242                 0.0              0.0                 0.0   \n",
       "5289                 0.0              0.0                 0.0   \n",
       "5340                 0.0              0.0                 0.0   \n",
       "5389                 0.0              0.0                 0.0   \n",
       "5429                 0.0              0.0                 0.0   \n",
       "5487                 0.0              0.0                 0.0   \n",
       "5521                 0.0              0.0                 0.0   \n",
       "5585                 0.0              0.0                 0.0   \n",
       "5639                 0.0              0.0                 0.0   \n",
       "5680                 0.0              0.0                 0.0   \n",
       "5739                 0.0              0.0                 0.0   \n",
       "5791                 0.0              0.0                 0.0   \n",
       "5843                 0.0              0.0                 0.0   \n",
       "5895                 0.0              0.0                 0.0   \n",
       "5947                 0.0              0.0                 0.0   \n",
       "6000                 0.0              0.0                 0.0   \n",
       "6052                 0.0              0.0                 0.0   \n",
       "6096                 0.0              0.0                 0.0   \n",
       "6149                 0.0              0.0                 0.0   \n",
       "6208                 0.0              0.0                 0.0   \n",
       "6263                 0.0              0.0                 0.0   \n",
       "6315                 0.0              0.0                 0.0   \n",
       "6369                 0.0              0.0                 0.0   \n",
       "6422                 0.0              0.0                 0.0   \n",
       "6475                 0.0              0.0                 0.0   \n",
       "6528                 0.0              0.0                 0.0   \n",
       "6565                 0.0              0.0                 0.0   \n",
       "6633                 0.0              0.0                 0.0   \n",
       "6690                 0.0              0.0                 0.0   \n",
       "\n",
       "     type_TRAFFIC_LIGHT type_VEHICLE  \n",
       "4254                0.0          1.0  \n",
       "4298                0.0          1.0  \n",
       "4350                0.0          1.0  \n",
       "4393                0.0          1.0  \n",
       "4443                0.0          1.0  \n",
       "4485                0.0          1.0  \n",
       "4532                0.0          1.0  \n",
       "4578                0.0          1.0  \n",
       "4623                0.0          1.0  \n",
       "4665                0.0          1.0  \n",
       "4712                0.0          1.0  \n",
       "4757                0.0          1.0  \n",
       "4791                0.0          1.0  \n",
       "4848                0.0          1.0  \n",
       "4899                0.0          1.0  \n",
       "4941                0.0          1.0  \n",
       "4997                0.0          1.0  \n",
       "5046                0.0          1.0  \n",
       "5095                0.0          1.0  \n",
       "5144                0.0          1.0  \n",
       "5193                0.0          1.0  \n",
       "5242                0.0          1.0  \n",
       "5289                0.0          1.0  \n",
       "5340                0.0          1.0  \n",
       "5389                0.0          1.0  \n",
       "5429                0.0          1.0  \n",
       "5487                0.0          1.0  \n",
       "5521                0.0          1.0  \n",
       "5585                0.0          1.0  \n",
       "5639                0.0          1.0  \n",
       "5680                0.0          1.0  \n",
       "5739                0.0          1.0  \n",
       "5791                0.0          1.0  \n",
       "5843                0.0          1.0  \n",
       "5895                0.0          1.0  \n",
       "5947                0.0          1.0  \n",
       "6000                0.0          1.0  \n",
       "6052                0.0          1.0  \n",
       "6096                0.0          1.0  \n",
       "6149                0.0          1.0  \n",
       "6208                0.0          1.0  \n",
       "6263                0.0          1.0  \n",
       "6315                0.0          1.0  \n",
       "6369                0.0          1.0  \n",
       "6422                0.0          1.0  \n",
       "6475                0.0          1.0  \n",
       "6528                0.0          1.0  \n",
       "6565                0.0          1.0  \n",
       "6633                0.0          1.0  \n",
       "6690                0.0          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[(dataset['situation_label'] == 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of elements in src_labels that are 1 is: 50\n"
     ]
    }
   ],
   "source": [
    "count = np.sum(src_labels == 1)\n",
    "\n",
    "print(f\"The number of elements in src_labels that are 1 is: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.from_numpy(sources.astype(np.int64)).to(torch.long)          # Maybe a problem?\n",
    "t = torch.from_numpy(timestamps.astype(np.int64)).to(torch.long)\n",
    "y = torch.from_numpy(src_labels.astype(np.float64)).to(torch.float)\n",
    "\n",
    "source_node_features=torch.from_numpy(node_features.astype(np.float64)).to(torch.float) \n",
    "\n",
    "path = memory_dataset_path\n",
    "\n",
    "data = TemporalData(src=src,  t=t, y=y, source_node_features=source_node_features)\n",
    "torch.save(InMemoryDataset.collate([data]), path)\n",
    "data, slices = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalData(src=[6720], t=[6720], y=[6720], source_node_features=[6720, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = data.train_val_test_split(val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 4727, 1.0: 11})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "plot_label_distribution(train_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loader = TemporalDataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.bs,\n",
    "    # neg_sampling_ratio=1.0,\n",
    ")\n",
    "val_loader = TemporalDataLoader(\n",
    "    val_data,\n",
    "    batch_size=args.bs,\n",
    "    # neg_sampling_ratio=1.0,\n",
    ")\n",
    "test_loader = TemporalDataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.bs,\n",
    "    # neg_sampling_ratio=1.0,\n",
    ")\n",
    "neighbor_loader = LastNeighborLoader(data.num_nodes, size=10, device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'msg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x, edge_index, edge_attr)\n\u001b[1;32m     15\u001b[0m memory_dim \u001b[39m=\u001b[39m time_dim \u001b[39m=\u001b[39m embedding_dim \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m     17\u001b[0m memory \u001b[39m=\u001b[39m TGNMemory(\n\u001b[1;32m     18\u001b[0m     data\u001b[39m.\u001b[39mnum_nodes,\n\u001b[0;32m---> 19\u001b[0m     data\u001b[39m.\u001b[39;49mmsg\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     20\u001b[0m     memory_dim,\n\u001b[1;32m     21\u001b[0m     time_dim,\n\u001b[1;32m     22\u001b[0m     message_module\u001b[39m=\u001b[39mIdentityMessage(data\u001b[39m.\u001b[39mmsg\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), memory_dim, time_dim),\n\u001b[1;32m     23\u001b[0m     aggregator_module\u001b[39m=\u001b[39mLastAggregator(),\n\u001b[1;32m     24\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m gnn \u001b[39m=\u001b[39m GraphAttentionEmbedding(\n\u001b[1;32m     27\u001b[0m     in_channels\u001b[39m=\u001b[39mmemory_dim,\n\u001b[1;32m     28\u001b[0m     out_channels\u001b[39m=\u001b[39membedding_dim,\n\u001b[1;32m     29\u001b[0m     msg_dim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mmsg\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     30\u001b[0m     time_enc\u001b[39m=\u001b[39mmemory\u001b[39m.\u001b[39mtime_enc,\n\u001b[1;32m     31\u001b[0m )\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/temporal.py:136\u001b[0m, in \u001b[0;36mTemporalData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/storage.py:82\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     81\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     83\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'msg'"
     ]
    }
   ],
   "source": [
    "\n",
    "class GraphAttentionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        edge_dim = msg_dim + time_enc.out_channels\n",
    "        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2,\n",
    "                                    dropout=0.1, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, last_update, edge_index, t, msg):\n",
    "        rel_t = last_update[edge_index[0]] - t\n",
    "        rel_t_enc = self.time_enc(rel_t.to(x.dtype))\n",
    "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
    "        return self.conv(x, edge_index, edge_attr)\n",
    "\n",
    "memory_dim = time_dim = embedding_dim = 20\n",
    "\n",
    "memory = TGNMemory(\n",
    "    data.num_nodes,\n",
    "    data.msg.size(-1),\n",
    "    memory_dim,\n",
    "    time_dim,\n",
    "    message_module=IdentityMessage(data.msg.size(-1), memory_dim, time_dim),\n",
    "    aggregator_module=LastAggregator(),\n",
    ").to(device)\n",
    "\n",
    "gnn = GraphAttentionEmbedding(\n",
    "    in_channels=memory_dim,\n",
    "    out_channels=embedding_dim,\n",
    "    msg_dim=data.msg.size(-1),\n",
    "    time_enc=memory.time_enc,\n",
    ").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNClassifier(torch.nn.Module):\n",
    "    def __init__(self, node_features = 17, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        output = self.conv2(x, edge_index)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class MLP(torch.nn.Module):\n",
    "  def __init__(self, dim, drop=0.3):\n",
    "    super().__init__()\n",
    "    self.fc_1 = torch.nn.Linear(dim, 10)\n",
    "    self.fc_3 = torch.nn.Linear(10, 1)\n",
    "    self.act = torch.nn.ReLU()\n",
    "    self.dropout = torch.nn.Dropout(p=drop, inplace=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.act(self.fc_1(x))\n",
    "    x = self.dropout(x)\n",
    "    return self.fc_3(x).squeeze(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.lin_src = Linear(in_channels, in_channels)\n",
    "        self.lin_dst = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
    "        h = h.relu()\n",
    "        return self.lin_final(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GCNClassifier(node_features=17, num_classes=2).to(device)\n",
    "\n",
    "decoder = MLP(20).to(device)\n",
    "# decoder_optimizer = torch.optim.Adam(set(memory.parameters()) | set(gnn.parameters()) | set(decoder.parameters()), lr=0.001)\n",
    "\n",
    "# link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
    "optimizer = torch.optim.Adam(set(memory.parameters()) | set(gnn.parameters()) | set(decoder.parameters()), lr=0.0001)\n",
    "\n",
    "# criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of batches: 706\n",
      "Trainings batch loaded: 0 / 706\n",
      "Trainings batch loaded: 100 / 706\n",
      "Trainings batch loaded: 200 / 706\n",
      "Trainings batch loaded: 300 / 706\n",
      "Trainings batch loaded: 400 / 706\n",
      "Trainings batch loaded: 500 / 706\n",
      "Trainings batch loaded: 600 / 706\n",
      "Trainings batch loaded: 700 / 706\n",
      "Epoch: 01, Loss: 0.8031\n",
      "Test batch loaded: 0 / 152\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Test batch loaded: 100 / 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Test batch loaded: 0 / 151\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Test batch loaded: 100 / 151\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Skipped ROC AUC computation for this batch as it contains only one class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ROC AUC computation for this batch as it contains only one class.\n",
      "Val AP: 0.1047, Val AUC: 0.4742\n",
      "Test AP: 0.1781, Test AUC: 0.5332\n",
      "Length of batches: 706\n",
      "Trainings batch loaded: 0 / 706\n",
      "Trainings batch loaded: 100 / 706\n",
      "Trainings batch loaded: 200 / 706\n",
      "Trainings batch loaded: 300 / 706\n",
      "Trainings batch loaded: 400 / 706\n",
      "Trainings batch loaded: 500 / 706\n",
      "Trainings batch loaded: 600 / 706\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 147\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m folder_path\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m):\n\u001b[0;32m--> 147\u001b[0m     train_loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m    148\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m    150\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[17], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m neighbor_loader\u001b[39m.\u001b[39minsert(batch\u001b[39m.\u001b[39msrc, batch\u001b[39m.\u001b[39mdst)\n\u001b[1;32m     57\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 58\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     59\u001b[0m memory\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     61\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(loss) \u001b[39m*\u001b[39m batch\u001b[39m.\u001b[39mnum_events\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def plot_embeddings(embeddings, epoch, folder_path, file_name):\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    tsne = TSNE(n_components=2)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], marker='o', s=5)\n",
    "    plt.title(f'Embeddings at Epoch {epoch}')\n",
    "    \n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "def train():\n",
    "    memory.train()\n",
    "    gnn.train()\n",
    "    decoder.train()\n",
    "    # link_pred.train()\n",
    "\n",
    "    memory.reset_state()  # Start with a fresh memory.\n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "    total_loss = 0\n",
    "    overall_batches = len(train_loader)\n",
    "    \n",
    "    print(f\"Length of batches: {overall_batches}\")\n",
    "    \n",
    "    for k, batch in enumerate(train_loader):\n",
    "    # for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "        \n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device))\n",
    "        \n",
    "        hidden_state = z[assoc[batch.src]]\n",
    "\n",
    "        out = decoder(hidden_state)\n",
    "        pred = out.sigmoid()\n",
    "        \n",
    "        loss = criterion(pred, batch.y)\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        memory.detach()\n",
    "        \n",
    "        total_loss += float(loss) * batch.num_events\n",
    "        \n",
    "        if k % 100 == 0:\n",
    "            print(f\"Trainings batch loaded: {k} / {overall_batches}\"\"\")\n",
    "\n",
    "    return total_loss / train_data.num_events\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    memory.eval()\n",
    "    gnn.eval()\n",
    "    # link_pred.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "\n",
    "    total_loss = 0\n",
    "    torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
    "    \n",
    "    overall_batches = len(loader)\n",
    "    aps, aucs = [], []\n",
    "    \n",
    "    for k, batch in enumerate(loader):\n",
    "    \n",
    "        batch = batch.to(device)\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device))\n",
    "\n",
    "        out = decoder(z[assoc[batch.src]])        \n",
    "        # out = classifier(z[assoc[batch.src]])\n",
    "        \n",
    "        pred = out.sigmoid()\n",
    "        loss = criterion(pred, batch.y)\n",
    "        \n",
    "        aps.append(average_precision_score(batch.y, pred))\n",
    "        \n",
    "        if len(np.unique(batch.y.cpu().numpy())) > 1:\n",
    "            aucs.append(roc_auc_score(batch.y, pred))\n",
    "        else:\n",
    "            print(\"Skipped ROC AUC computation for this batch as it contains only one class.\")\n",
    "\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "        \n",
    "        total_loss += float(loss) * batch.num_events\n",
    "        if k % 100 == 0:\n",
    "            print(f\"Test batch loaded: {k} / {overall_batches}\"\"\")\n",
    "        \n",
    "    return float(torch.tensor(aps).mean()), float(torch.tensor(aucs).mean()), total_loss \n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "def get_node_embedding_output_folder_path():\n",
    "    \n",
    "    if BUILD_DEVICE == 'local':\n",
    "        folder_path = '/app/graph_playground/data/output/node_embeddings'\n",
    "    elif BUILD_DEVICE == 'server':\n",
    "        folder_path = '/export/home/s2995839/iot-unsw-2/output/node_embeddings'\n",
    "        \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "def get_loss_output_path():\n",
    "    \n",
    "    if BUILD_DEVICE == 'local':\n",
    "        folder_path = '/app/graph_playground/data/output/trainings_process'\n",
    "    elif BUILD_DEVICE == 'server':\n",
    "        folder_path = '/export/home/s2995839/iot-unsw-2/output/trainings_process'\n",
    "        \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    train_loss = train()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        n_id = torch.arange(memory.num_nodes, device=device)  # assuming memory has num_nodes attribute to get all nodes\n",
    "        embeddings, _ = memory(n_id)\n",
    "        output_path_node_embedding = get_node_embedding_output_folder_path()\n",
    "        plot_embeddings(embeddings, epoch, folder_path=output_path_node_embedding, file_name=f'Node_Embedding_Epoch_{epoch}.png')\n",
    "    \n",
    "    print(f'Epoch: {epoch:02d}, Loss: {train_loss:.4f}')\n",
    "    \n",
    "    val_ap, val_auc, val_loss = test(val_loader)\n",
    "    validation_losses.append(val_loss)    \n",
    "    test_ap, test_auc, test_loss = test(test_loader)\n",
    "    \n",
    "    print(f'Val AP: {val_ap:.4f}, Val AUC: {val_auc:.4f}')\n",
    "    print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}')\n",
    "    \n",
    "    if early_stopper.early_stop(val_loss):         \n",
    "        print(f\"Early stopping: {epoch} epochs\")    \n",
    "        break\n",
    "    \n",
    "    \n",
    "def plot_trainings_loss(output_trainings_loss_path):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(validation_losses, label='Validation Loss')\n",
    "    plt.title('Loss Evolution')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot in the specified folder\n",
    "    plt.savefig(os.path.join(output_trainings_loss_path, 'loss_evolution.png'))\n",
    "    plt.close()\n",
    "\n",
    "output_trainings_loss = get_loss_output_path()\n",
    "plot_trainings_loss(output_trainings_loss)\n",
    "\n",
    "\n",
    "def get_model_output_path():\n",
    "    \n",
    "    if BUILD_DEVICE == 'local':\n",
    "        folder_path = '/app/graph_playground/data/output/tgn-model'\n",
    "    elif BUILD_DEVICE == 'server':\n",
    "        folder_path = '/export/home/s2995839/iot-unsw-2/output/tgn-model'\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "\n",
    "model_output_path = get_model_output_path()\n",
    "model_file_path = os.path.join(model_output_path, \"your_model_name.pt\")\n",
    "torch.save(gnn.state_dict(), model_file_path)\n",
    "\n",
    "\n",
    "# Load \n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code for Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_embeddings(embeddings, labels, epoch):\n",
    "#     tsne = TSNE(n_components=2)\n",
    "#     reduced_embeddings = tsne.fit_transform(embeddings.cpu().detach().numpy())\n",
    "\n",
    "#     colors = ['red' if label == 1 else 'blue' for label in labels]\n",
    "\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=colors, marker='o', s=5)\n",
    "#     plt.title(f'Embeddings at Epoch {epoch}')\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(validation_losses, label='Validation Loss')\n",
    "# plt.title('Loss Evolution')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# def train():\n",
    "#     memory.train()\n",
    "#     gnn.train()\n",
    "#     # classifier.train()\n",
    "#     decoder.train()\n",
    "\n",
    "#     memory.reset_state()  # Start with a fresh memory.\n",
    "#     neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "#     total_loss = 0\n",
    "#     overall_batches = len(train_loader)\n",
    "    \n",
    "#     print(f\"Length of batches: {overall_batches}\")\n",
    "    \n",
    "#     for k, batch in enumerate(train_loader):\n",
    "#     # for batch in train_loader:\n",
    "#         decoder_optimizer.zero_grad()\n",
    "#         batch = batch.to(device)\n",
    "\n",
    "#         n_id = torch.cat([batch.src, batch.dst]).unique()\n",
    "#         n_id, edge_index, e_id = neighbor_loader(n_id)\n",
    "        \n",
    "#         assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "#         z, last_update = memory(n_id)\n",
    "#         z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "#                 data.msg[e_id].to(device))\n",
    "\n",
    "#         hidden_state = z[assoc[batch.src]]\n",
    "\n",
    "        \n",
    "        \n",
    "#         # plot_embeddings(hidden_state, k)\n",
    "        \n",
    "#         out = decoder(hidden_state)\n",
    "#         pred = out.sigmoid()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         loss = criterion(pred, batch.y)\n",
    "\n",
    "#         memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "#         neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "#         loss.backward()\n",
    "#         decoder_optimizer.step()\n",
    "#         memory.detach()\n",
    "        \n",
    "#         total_loss += float(loss) * batch.num_events\n",
    "#         if k % 100 == 0:\n",
    "#             print(f\"Trainings batch loaded: {k} / {overall_batches}\"\"\")\n",
    "\n",
    "#     return total_loss / train_data.num_events\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def test(loader):\n",
    "#     memory.eval()\n",
    "#     gnn.eval()\n",
    "#     classifier.eval()\n",
    "\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
    "#     overall_batches = len(loader)\n",
    "\n",
    "#     aps, aucs = [], []\n",
    "    \n",
    "#     for k, batch in enumerate(loader):\n",
    "    \n",
    "#         batch = batch.to(device)\n",
    "        \n",
    "#         batch_size = BATCH_SIZE\n",
    "#         num_instance = len(data.src)\n",
    "        \n",
    "#         s_idx = k * batch_size\n",
    "#         e_idx = min(num_instance, s_idx + batch_size)\n",
    "\n",
    "#         n_id = torch.cat([batch.src, batch.dst]).unique()\n",
    "#         n_id, edge_index, e_id = neighbor_loader(n_id)\n",
    "\n",
    "#         assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "#         z, last_update = memory(n_id)\n",
    "#         z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "#                 data.msg[e_id].to(device))\n",
    "        \n",
    "#         # plot_embeddings(z, k)\n",
    "#         # plot_embeddings(z, batch.y.cpu().numpy(), k)\n",
    "\n",
    "#         plot_embeddings(z[assoc[batch.src]], batch.y.cpu().numpy(), k)\n",
    "\n",
    "        \n",
    "#         out = decoder(z[assoc[batch.src]])\n",
    "#         # out = classifier(z[assoc[batch.src]])\n",
    "#         pred = out.sigmoid()\n",
    "    \n",
    "#         memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "#         neighbor_loader.insert(batch.src, batch.dst)\n",
    "        \n",
    "#         true_labels_loss = batch.y\n",
    "#         predicted_scores_loss = pred\n",
    "#         true_labels = batch.y.cpu().numpy()\n",
    "#         predicted_scores = pred.cpu().numpy()\n",
    "        \n",
    "#         loss = criterion(predicted_scores_loss, true_labels_loss)\n",
    "    \n",
    "    \n",
    "#         ap = average_precision_score(true_labels, predicted_scores)\n",
    "#         # auc = roc_auc_score(true_labels, predicted_scores)\n",
    "    \n",
    "#         aps.append(ap)\n",
    "#         # aucs.append(auc)\n",
    "        \n",
    "#         total_loss += float(loss) * batch.num_events\n",
    "#         if k % 100 == 0:\n",
    "#             print(f\"Test batch loaded: {k} / {overall_batches}\"\"\")\n",
    "        \n",
    "        \n",
    "        \n",
    "#     return float(torch.tensor(aps).mean()), total_loss \n",
    "\n",
    "# train_losses = []\n",
    "# validation_losses = []\n",
    "\n",
    "# for epoch in range(1, 51):\n",
    "#     train_loss = train()\n",
    "#     train_losses.append(train_loss)\n",
    "    \n",
    "#     # with torch.no_grad():\n",
    "#     #     n_id = torch.arange(memory.num_nodes, device=device)  # assuming memory has num_nodes attribute to get all nodes\n",
    "#     #     embeddings, _ = memory(n_id)\n",
    "#     #     plot_embeddings(embeddings, epoch)\n",
    "    \n",
    "#     print(f'Epoch: {epoch:02d}, Loss: {train_loss:.4f}')\n",
    "#     val_ap, val_loss = test(val_loader)\n",
    "#     validation_losses.append(val_loss)    \n",
    "#     test_ap, _ = test(test_loader)\n",
    "    \n",
    "#     if early_stopper.early_stop(val_loss):         \n",
    "#         print(f\"Early stopping: {epoch} epochs\")    \n",
    "#         break\n",
    "    \n",
    "#     print(f'Val AP: {val_ap:.4f}')\n",
    "#     print(f'Test AP: {test_ap:.4f}')\n",
    "    \n",
    "#     # val_ap, val_auc = test(val_loader)\n",
    "#     # test_ap, test_auc = test(test_loader)\n",
    "#     # print(f'Val AP: {val_ap:.4f}, Val AUC: {val_auc:.4f}')\n",
    "#     # print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     set(memory.parameters()) | set(gnn.parameters())\n",
    "#     | set(link_pred.parameters()), lr=0.0001)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# # Helper vector to map global node indices to local ones.\n",
    "# assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "# def train():\n",
    "#     memory.train()\n",
    "#     gnn.train()\n",
    "#     link_pred.train()\n",
    "\n",
    "#     memory.reset_state()  # Start with a fresh memory.\n",
    "#     neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "#     total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         batch = batch.to(device)\n",
    "\n",
    "#         n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "#         assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "#         # Get updated memory of all nodes involved in the computation.\n",
    "#         z, last_update = memory(n_id)\n",
    "#         z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "#                 data.msg[e_id].to(device))\n",
    "#         pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "#         neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "#         loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "#         loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "#         # Update memory and neighbor loader with ground-truth state.\n",
    "#         memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "#         neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         memory.detach()\n",
    "#         total_loss += float(loss) * batch.num_events\n",
    "\n",
    "#     return total_loss / train_data.num_events\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def test(loader):\n",
    "#     memory.eval()\n",
    "#     gnn.eval()\n",
    "#     link_pred.eval()\n",
    "\n",
    "#     torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
    "\n",
    "#     aps, aucs = [], []\n",
    "#     for batch in loader:\n",
    "#         batch = batch.to(device)\n",
    "\n",
    "#         n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "#         assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "#         z, last_update = memory(n_id)\n",
    "#         z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "#                 data.msg[e_id].to(device))\n",
    "#         pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "#         neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "#         y_pred = torch.cat([pos_out, neg_out], dim=0).sigmoid().cpu()\n",
    "#         y_true = torch.cat(\n",
    "#             [torch.ones(pos_out.size(0)),\n",
    "#              torch.zeros(neg_out.size(0))], dim=0)\n",
    "\n",
    "#         aps.append(average_precision_score(y_true, y_pred))\n",
    "#         aucs.append(roc_auc_score(y_true, y_pred))\n",
    "\n",
    "#         memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "#         neighbor_loader.insert(batch.src, batch.dst)\n",
    "#     return float(torch.tensor(aps).mean()), float(torch.tensor(aucs).mean())\n",
    "\n",
    "\n",
    "# for epoch in range(1, 51):\n",
    "#     loss = train()\n",
    "#     print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "#     val_ap, val_auc = test(val_loader)\n",
    "#     test_ap, test_auc = test(test_loader)\n",
    "#     print(f'Val AP: {val_ap:.4f}, Val AUC: {val_auc:.4f}')\n",
    "#     print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
